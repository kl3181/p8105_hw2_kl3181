p8105\_hw2\_kl3181
================
Kelley Lou

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.1     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read in Mr. Trashweel data set and clean.

``` r
trashwheel_df = read_xlsx(
  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "Mr. Trash Wheel",
      range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>% 
  mutate(
      sports_balls = round(sports_balls),
      sports_balls = as.integer(sports_balls)
  )
```

Read in precipitation data for 2018 and 2017.

``` r
precip_2018 = read_excel(
  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "2018 Precipitation", 
      skip = 1
      ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = read_excel(
  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "2017 Precipitation",
      skip = 1
      ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine annual precipitation dataframes. This can be done with a
“helper” tibble that contains pairs of numeric and character ways of
representing month, and then merge with precipitation dataset.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

precip_df = 
  left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr.Trashweel trash collector
in Baltimore, Maryland. As trash enters the inner harbor, the trashweel
collects that trash, and then stores it in a dumpster. The dataset
contains information on year, month, and trash collected, including some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data. There
are variables including dumpster, month, year, date, weight\_tons,
volume\_cubic\_yards, plastic\_bottles, polystyrene, cigarette\_butts,
glass\_bottles, grocery\_bags, chip\_bags, sports\_balls, homes\_powered
and has data from 2014 to 2019. The median number of sports balls in
2017 was 8. The total precipitation in 2017 was 32.93 inches. In 2018,
it was 70.33 inches.

## Problem 2

\#\#\#\#\#Read in NYC transit dataset and clean.

``` r
transit_df =  read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
    janitor::clean_names() %>%
    select(line:entry, vending, ada) %>% 
    mutate(
      entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE"
    ), 
)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This dataset focuses on NYC transit data, with information related to
each entrance and exit for each subway station in NYC. After cleaning
the dataset, the dataset contains variables line, station\_name,
station\_latitude, station\_longitude, route1, route2, route3, route4,
route5, route6, route7, route8, route9, route10, route11,
entrance\_type, entry, vending, ada. The clean\_names function was
utilized in the janitor package. The entry variable was changed from
character to logical. Additionally, there are a total of 1868 rows and
19 columns. The data is not tidy because the route number and route name
are not distinct variables.

##### Data Related Questions

There are 465 distinct stations, 84 stations are ADA compliant and
37.704918 percent of entrances/exits without vending allow entrance.

##### Reformat data

``` r
transit_reformat = 
  transit_df %>% 
  mutate_at(vars(route8:route11), as.character) %>% 
  pivot_longer(
    route1:route11, 
    names_to = "route_num", 
    values_to = "route_name") %>% 
  drop_na(route_name)

A_train = transit_reformat %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name, .keep_all = TRUE)

ADA_A = A_train %>% 
  filter(ada == TRUE)
```

There are 60 distinct stations serving the A train. Among these
stations, 17 are ADA compliant.

## Problem 3

Reading in and cleaning pols-month data.

``` r
pols_month_df = read_csv(
  "./data/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
month_pols =
  tibble(
    month = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"),
    month_name = month.name
  ) %>% view

pols_tidy_df = left_join(pols_month_df, month_pols, by = "month") %>%
  relocate(month_name) %>%
  mutate(
    president = recode(prez_dem,`1` = "dem", `0` = "gop")) %>%
  select(-month, -prez_dem, -prez_gop, -day) 
```

Reading in and cleaning snp data.

``` r
snp_df = read_csv(
  "./data/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"))
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
month_snp =
  tibble(
    month = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"),
    month_name = month.name
  )

snp_tidy_df = left_join(snp_df, month_snp, by = "month") %>%
  arrange(year, month) %>%
  relocate(year, month_name) %>%
  select(-month, -day) 
```

Reading in and cleaning unemployment data.

``` r
unemployment_df = read_csv(
  "./data/unemployment.csv") %>%
  janitor::clean_names() %>%
  rename(January = jan, February = feb, March = mar, April = apr, May = may, June = jun, July = jul, August = aug, September = sep, October = oct, November = nov, December = dec) %>% 
  pivot_longer(
    January:December,
    names_to = "month_name",
    values_to = "unemployment"
  ) %>% 
  mutate(
    year = as.character(year)) 
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Join the datasets. First, merge snp into pols. Then, merge in
unemployment.

``` r
snp_pols_df = left_join(pols_tidy_df, snp_tidy_df, by = c("year" = "year", "month_name" = "month_name"))

final_df = left_join(snp_pols_df, unemployment_df, by = c("year" = "year", "month_name" = "month_name"))
```

The initial pols dataset contains 822 observations of 9 variables
related to the number of national politicians who are democratic or
republican at any time as well as the date and indication of whether the
president was democratic or republican. To tidy the resulting dataset, I
separated the date into three new variables: month, year and day and
then removing day in order to merge with the other datasets. Then, I
converted the months into the full names and created a new president
variable, allowing us to see the party of the president easier. The
tidied dataset also has 822 rows and 9 columns, with a date range from
1947-2015.

The initial snp dataset contains 787 observations of 2 variables (date
and close) related to the S\&P, which is often used as a representative
measure of the stock market as a whole. To tidy the dataset, I separated
the date into month, year and day, removing day. Then, the full month
name was appied to keep consistency. The tidied dataset has 787 rows and
3 columns, with a date range from 1950-2015.

The initial unemployment dataset contains 68 observations of 13
variables, with each variable indicating the percentage of unemployment
for each month as well as the year. To tidy the data and allow for
future merging, I transformed the months from columns into rows and then
changed the months to allow for consistency. The tidied dataset has 816
rows and 3 variables (year, month and unemployment) with a date range
from 1948-2015.

The final dataset merges all three of the other datasets: pols, snp, and
unemployment by year and month. This larger dataset contains 822 rows of
data and 11 columns. These variables provide information on politics,
the stock market as well as unemployment for different time periods
ranging from 1947-2015.
